library(swirl)
swirl()
x
x[1:10]
x[is.na(x)]
x[!is.na(x)]
y <- x[!is.na(x)]
y
y[y > 0]
x[x > 0]
x[!is.na(x) & x > 0]
x[c(3,5,7)]
x[0]
x[3000]
x[c(-2, -10)]
x[-c(2, 10)]
vect <- c(foo=11, bar=2, norf=NA)
vect
names(vect)
vect2 <- c(11,2,NA)
names(vect2 <- c("foo", "bar", "norf"))
names(vect2) <- c("foo", "bar", "norf"))
names(vect2) <- c("foo", "bar", "norf")
identical(vect, vect2)
vect["bar"]
vect[c("foo", "bar")]
load("C:/Users/Ägaren/Desktop/R/.Rhistory")
test <- c("hej", "ha")
test
cbind(test, "baba")
test+"baba"
test
library(datasets)
data(iris)
?iris
iris
x <- c(rnorm(10), runif(10), rnorm(10,1))
x
f <- gl(3, 10)
class(iris)
tapply(iris$Sepal.Length, iris$Species, mean)
colMeans(iris)
x
library(datasets)
data(iris)
?iris
iris
colMeans(iris)
?colMeans
?apply
apply(iris[, 1:4], 2, mean)
apply(iris, 2, mean)
apply(iris[, 1:4], 1, mean)
data(mtcars)
?mtcars
mtcars
?split
?sapply
tapply(mtcars$mpg, mtcars$cyl, mean)
tapply(mtcars$hp, mtcars$cyl, mean)
bajs <- tapply(mtcars$hp, mtcars$cyl, mean)
bajs
class(bajs)
bajs[1]
bajs[3]-bajs[1]
?ls
library(swirl)
swirl()
sapply(flags, unique)
vapply(flags, unique, numeric(1))
ok()
sapply(flags, class)
vapply(flags, class, character(1))
?tapply
table(flags$landmass)
table(flags$animate)
tapply(flags$animate, flags$landmass, mean)
tapply(flags$population, flags$red, summary)
tapply(flags$population, flags$landmass, summary)
swirl()
ls()
class(plants)
dim(plants)
nrow(plants)
ncol(plants)
object.size(plants)
names(plants)
head(plants)
head(plants, 10)
tail(plants, 15)
summary(plants)
table(plants$Active_Growth_Period)
str(plants)
?qunif
qunif(75)
qunif(0.75)
qunif(0.75, 4, 5)
?pnorm
pnorm(93, 100, 10)
pnorm(70, 80, 10)
qnorm(0.95, 1100, 75)
?qbinorm
?rbinom
?rpois
1 - ppois(3, 5)
ppois(3, 5, lower.tail=FALSE)
ppois(5, 5)
1 - ppois(3, 1)
1 - ppois(3, 2.5)
1-ppois(3, 2.5)
dpois(4, 2.5)
dpois(5, 2.5)
dpois(4, 2.5)+dpois(5, 2.5)
?pbinom
sum(dbinom(c(4,5),5,0.5))
ppois(10,15)
?punif
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 1000), lower.tail = FALSE), 3)
round(pnorm(.51, mean = 0.5, sd = sqrt(1 / 12 / 100), lower.tail = FALSE), 3)
14:16
x   <- seq(5,15,length=1000)
y   <- dnorm(x,mean=10, sd=3)
plot(x,y, type="l", lwd=1)
x   <- seq(5,15,length=1000)
y   <- dnorm(x,mean=15, sd=10)
plot(x,y, type="l", lwd=1)
x   <- seq(5,25,length=1000)
y   <- dnorm(x,mean=15, sd=10)
plot(x,y, type="l", lwd=1)
abline(v=c(14,16),lty=2,col="blue")
library(nlme)
library(lattice)
xyplot(weight ~ Time | Diet, BodyWeight)
?BodyWeight
?text
?panel.abline
?splom
?print.trellis
?par
?trellis.par.set
library(datasets)
data(airquality)
install.packages("lattice")
install.packages("lattice")
install.packages("ggplot2")
library(datasets)
data(airquality)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
library(ggplot2)
qplot(Wind, Ozone, data = airquality, geom = "smooth")
qplot(Wind, Ozone, data = airquality, facets = . ~ factor(Month))
qplot(Wind, Ozone, data = airquality)
airquality = transform(airquality, Month = factor(Month))
qplot(Wind, Ozone, data = airquality, facets = . ~ Month)
library(ggplot2)
g <- ggplot(movies, aes(votes, rating))
print(g)
qplot(votes, rating, data = movies)
qplot(votes, rating, data = movies) + geom_smooth()
qplot(votes, rating, data = movies) + stats_smooth("loess")
qplot(votes, rating, data = movies, smooth = "loess")
qplot(votes, rating, data = movies, panel = panel.loess)
x   <- seq(5,25,length=1000)
y   <- dnorm(x,mean=15, sd=10)
plot(x,y, type="l", lwd=1)
abline(v=c(14,16),lty=2,col="blue")
y   <- dnorm(x,mean=15, sd=1)
plot(x,y, type="l", lwd=1)
abline(v=c(14,16),lty=2,col="blue")
library(swirl)
install_from_swirl("Statistical Inference")
swirl()
33/36
deck
52
4/52
0
12/52
2/51
skip
skip()
skip()
skip()
# need to do 1000 simulations and compute the sample mean each time
# sample size or n
n=40
# number of simulations (degrees of freedom in the t-test)
nsim=1000
lambda<-0.2
set.seed(1000)
exp_mean<-1/lambda
exp_var<-1/lambda^2
data<-matrix(data=rexp(nsim*n,0.2),nrow = nsim)
# this computes the 1000 means for each simulation run
# each simulation run consists of 40 samples from an exponential distribution
sample_means<-apply(X = data,MARGIN = 1,mean)
# this computes the 1000 stdeviations for each simulation run
sample_variance<-apply(X = data,MARGIN=1,FUN = var)
#hist(means,breaks = 20)
#abline(v = exp_mean,col="red",lwd=2)
#hist(stdevs,breaks = 20)
#abline(v = sqrt(exp_var),col="red",lwd=2)
df<-data.frame(Sample_means=sample_means)
print("Mean of sample means", mean(sample_means))
ggplot(df,aes(Sample_means))+geom_histogram(aes(Sample_means,color="Count"),binwidth=0.25)+
labs(title=’Distribution of sample means’,x=’Sample Mean’,y=’Frequency’)+
geom_vline(aes(xintercept=mean(sample_means),color="Mean of sample means",col="red"),size=1.5)+
geom_vline(aes(xintercept=5,color="Expected Mean of population",col="blue"),size=1.5)
library(ggplot2)
# need to do 1000 simulations and compute the sample mean each time
# sample size or n
n=40
# number of simulations (degrees of freedom in the t-test)
nsim=1000
lambda<-0.2
set.seed(1000)
exp_mean<-1/lambda
exp_var<-1/lambda^2
data<-matrix(data=rexp(nsim*n,0.2),nrow = nsim)
# this computes the 1000 means for each simulation run
# each simulation run consists of 40 samples from an exponential distribution
sample_means<-apply(X = data,MARGIN = 1,mean)
# this computes the 1000 stdeviations for each simulation run
sample_variance<-apply(X = data,MARGIN=1,FUN = var)
#hist(means,breaks = 20)
#abline(v = exp_mean,col="red",lwd=2)
#hist(stdevs,breaks = 20)
#abline(v = sqrt(exp_var),col="red",lwd=2)
df<-data.frame(Sample_means=sample_means)
print("Mean of sample means", mean(sample_means))
ggplot(df,aes(Sample_means))+geom_histogram(aes(Sample_means,color="Count"),binwidth=0.25)+
labs(title=’Distribution of sample means’,x=’Sample Mean’,y=’Frequency’)+
geom_vline(aes(xintercept=mean(sample_means),color="Mean of sample means",col="red"),size=1.5)+
geom_vline(aes(xintercept=5,color="Expected Mean of population",col="blue"),size=1.5)
# need to do 1000 simulations and compute the sample mean each time
# sample size or n
n=40
# number of simulations (degrees of freedom in the t-test)
nsim=1000
lambda<-0.2
set.seed(1000)
exp_mean<-1/lambda
exp_var<-1/lambda^2
data<-matrix(data=rexp(nsim*n,0.2),nrow = nsim)
# this computes the 1000 means for each simulation run
# each simulation run consists of 40 samples from an exponential distribution
sample_means<-apply(X = data,MARGIN = 1,mean)
# this computes the 1000 stdeviations for each simulation run
sample_variance<-apply(X = data,MARGIN=1,FUN = var)
hist(means,breaks = 20)
abline(v = exp_mean,col="red",lwd=2)
hist(stdevs,breaks = 20)
abline(v = sqrt(exp_var),col="red",lwd=2)
?geom_vline
View(df)
print("Mean of sample means", mean(sample_means))
mean(sample_means)
mean(sample_variance)
df2<-data.frame(Sample_Variance=sample_variance)
ggplot(df2,aes(Sample_Variance))+geom_histogram(aes(Sample_Variance,color="Count"),binwidth=1)+
labs(title=’Distribution of sample variances’,x=’Sample Variance’,y=’Frequency’)+
geom_vline(aes(xintercept=mean(sample_variance),color="Mean of sample variances"),size=1)+
geom_vline(aes(xintercept=25,color="Expected Mean of sample variances"),size=1)
View(data)
?apply
set.seed(1000)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*samples, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
set.seed(1000)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
mean(sample_variance)/40
sd(row_means)
sd(row_means)^2
mean(sample_variance)/39
set.seed(3)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
sd(row_means)^2
sd(sample_means)^2
set.seed(1000)
lambda <- 0.2
num_sim <- 1000
sample_size <- 40
sim <- matrix(rexp(num_sim*sample_size, rate=lambda), num_sim, sample_size)
row_means <- rowMeans(sim)
sd(row_means)^2
mean(sample_variance)
sd(sample_means)^2
nisse <- data.frame(base=c(140,138,150,148,135), weektwo=c(132,135,151,146,130))
nisse
?t.test
library(swirl)
swirl()
pt(q=2.5, df=15, lower.tail=falce)
?pt
fee
skip()
?qnorm
qnorm(0.95, 30)
qnorm(0.95
)
qnorm(0.99)
pnorm(2)
pnorm(2, lower.tail=FALCE)
pnorm(2, lower.tail=FALSE)
mybin
pbinom(6, size=8, prob=.5, lower.tail=FALSE)
pbinom(7, size=8, prob=.5, lower.tail=T)
pbinom(7, size=8, prob=.5, lower.tail=TRUE)
ppois(9, 5)
ppois(9, 5, lower.tail=FALSE)
View(nisse)
t.test(nisse[,1], nisse[,2], paired=TRUE, alternative="two.sided", var.equal=FALSE)$p.value
1100+c(-1,1)*qnorm(.975)*30/sqrt(9)
pbinom(2,size=4, prob=.5, lower.tail=FALSE)
ppois(10, 17.78)
ppois(10, 17.78, lower.tail=FALSE)
power.t.test(n=100, delta=.01, sd=.04, type="one.sample", alt="one.sided")$power
?rnorm
rnorm(9, -3, 1.5)
kuk <- data.frame(treat=rnorm(9,-3,1.5), plac=rnorm(9, 1, 1.8))
kuk
?t.test
hej <- data.frame()
t.test(kuk$treat, kuk$plac)
power.t.test(power=.9, delta=.01, sd=.04, type="one.sample", alt="one.sided")$n
1100+c(-1,1)*qt(0.975, 8)*30/sqrt(9)
mean(c(0.18, 0.18, -1.54, 0.42, 0.42, 0.42, 0.95))
x <- c(0.18, -1.54, 0.42, 0.95)
w <- c(2, 1, 3, 1)
x*w
mean(x*w)
x*w/7
sum(x*w)/7
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
?lm
z <- lm(y ~ x - 1)
plot(z)
plot(z)
summary(z)
mtcars
t
tr
tr <- lm(mpg ~ wt, data=mtcars)
summary(tr)
6x <- c(8.58, 10.46, 9.01, 9.64, 8.86)
six <- c(8.58, 10.46, 9.01, 9.64, 8.86)
six-mean(six)
mean(six)
scale(six)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
bajs <- lm(y ~ x)
summary(bajs)
x <- c(-3,-2,-1,0,1,2,3)
y <- c(-6, -4, -2, 0, 2, 4, 6)
bajs <- lm(y ~ x)
x <- c(-3,-2,-1,0,1,2,3)
y <- c(-6, -4, -2, 0, 2, 4, 6)
summary(bajs)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
bajs <- lm(y ~ x)
summary(bajs)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
beta
bet
gam
bet <- lm(y ~ x)
gam <- lm(x ~ y)
summary(bet)
summary(gam)
nisse <- x(-1.713, -0.04462)
nisse <- c(-1.713, -0.04462)
nisse
nisse[1]/nisse[2]
cor(x,y)
?sd
sd(x)/sd(y)
sd(x)/sd(y)*2
var(y)/var(x)
0.5*(4/2)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mu<-c(0.573,0.8,0.36,0.44)
mu
sapply(mu,function(mu){
sum( (x-mu)^2 )
})
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)$coefficients
summary(fit)
library(swirl)
rm(list=ls())
swirl()
install_from_swirl("Regression Models")
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)$coefficients
summary(fit)
mtcars
?lm
fitc
fitcars <- lm(mpg ~ weight, mtcars)
fitcars <- lm(mpg ~ wt, mtcars)
?predict
summary(fitcars)
predict(fitcars, mean(mtcars$wt), interval="confidence")
mtcars$wt
mean(mtcars$wt)
predict(fitcars, c(3.21725), interval="confidence")
summary(fitcars)
predict(fitcars, newdata=mean(mtcars$wt), interval="confidence")
mtcars2
mtcars2 <- mtcars
predict(fitcars, newdata=mean(mtcars2$wt), interval="confidence")
meanwt
meanwt <- data.frame(wt=mean(mtcars$wt))
meanwt
predict(fitcars, newdata=meanwt, interval="confidence")
?mtcars
meanwt <- data.frame(wt=c(mean(mtcars$wt),3))
meanwt
predict(fitcars, newdata=meanwt, interval="confidence")
predict(fitcars, newdata=meanwt, interval="prediction")
sumCoef <- summary(fitcars)$coefficients
fitcars$df
sumCoef
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fitcars$df) * sumCoef[2, 2]) / 1
(sumCoef[2,1] + c(-1, 1) * qt(.975, df = fitcars$df) * sumCoef[2, 2]) / 2
View(mtcars2)
answer <- (anova(lm(mpg ~ 1, mtcars))[2,2])/(anova(lm(mpg ~ wt, mtcars))[2])
answer
answer <- (anova(lm(mpg ~ wt, mtcars))[2,2])/(anova(lm(mpg ~ 1, mtcars))[2])
answer
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y ~ x)
summary(fit)
setwd("C:/R/repdata-013/RepData_PeerAssessment1")
setwd("C:/R/repdata-013/RepData_PeerAssessment2")
url
file
download
fileurl
fileurl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2""
fileurl <- "https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"
?unzip
?bzfile
data <- read.csv(bzfile("https://d396qusza40orc.cloudfront.net/repdata%2Fdata%2FStormData.csv.bz2"))
?download.file
download.file(fileurl, "./data/stormdatacsv.bz2")
download.file(fileurl, "./data/stormdatacsv.bz2")
data <- read.csv(bzfile("./data/stormdatacsv.bz2"))
View(data)
str(data)
summary(data)
download.file(fileurl, "./data/")
download.file(fileurl, "./data")
download.file(fileurl, "./data/hej.bz2")
download.file(fileurl, "./data/repdata-data-StormData.csv.bz2")
bz2file
bz2file <- "repdata-data-StormData.csv.bz2"
if(!file.exists(bz2file)) {download.file(fileurl, "repdata-data-StormData.csv.bz2")}
if(!file.exists(bz2file)) {download.file(fileurl, "repdata-data-StormData.csv.bz2")}
View(data)
unique(data$EVTYPE)
?aggregate
?toupper
summary(data)$EVTYPE
table(data$EVTYPE)
?table
nisse <- table(data$EVTYPE)
nisse[order(nisse)]
?plot
?head
